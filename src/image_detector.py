# -*- coding: utf-8 -*-
"""image_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HC78r30JdOX9aktD7cuDG3oY7JBN2_It

# **Image detector**
"""

import cv2
from skimage import metrics
import math as m

# Initial params
platform_length = 208 # mm
device_width = 50 # mm
device_height = 80 # mm

# def index_of_max_area(contours):
#   max_area = 0
#   max_index = -1
#   for idx, cnt in enumerate(contours):
#     if cv2.contourArea(cnt) > max_area:
#       max_area = cv2.contourArea(cnt)
#       max_index = idx
#   return max_index

# def crop(image, crop):
#   img_copy = image.copy()
#   crop = np.array(crop)
#   bounding_rect = cv2.boundingRect(crop)
#   img_cropped_bounding_rect = img_copy[bounding_rect[1]:bounding_rect[1] + bounding_rect[3],
#                                 bounding_rect[0]:bounding_rect[0] + bounding_rect[2]]
#   return img_cropped_bounding_rect

def get_platform_size(coords):
  btr = coords["bottom_right"]
  btl = coords["bottom_left"]
  tpr = coords["top_right"]
  h = m.sqrt((tpr[0] - btr[0])*(tpr[0] - btr[0])+(tpr[1] - btr[1])*(tpr[1] - btr[1]))
  w = m.sqrt((btl[0] - btr[0])*(btl[0] - btr[0])+(btl[1] - btr[1])*(btl[1] - btr[1]))
  return h, w


def find_optimal_scale(device_image_str, platform_coords):
  device_img_gray = cv2.imread(device_image_str, cv2.IMREAD_GRAYSCALE)
  h_device, w_device = device_img_gray.shape

  h_img, w_img = get_platform_size(platform_coords)
  pixels_per_millimeter = (w_img / platform_length + h_img / platform_length) / 2 # pixels per one millimeter in src image
  device_width_pixels = device_width * pixels_per_millimeter # pixels
  device_height_pixels = device_height * pixels_per_millimeter # pixels
  optimal_scale = (device_width_pixels / w_device + device_height_pixels / h_device) / 2
  return optimal_scale

def match_images(src_image_str, match_image_str, platform_coords, scale):
  img_gray = cv2.imread(src_image_str, cv2.IMREAD_GRAYSCALE)
  match_img_gray = cv2.imread(match_image_str, cv2.IMREAD_GRAYSCALE)

  # _, thresh_img = cv2.threshold(img_gray, 185, 255, cv2.THRESH_BINARY)
  # _, thresh_match = cv2.threshold(match_img_gray, 140, 255, cv2.THRESH_BINARY)

  thresh_img = img_gray
  thresh_match = match_img_gray

  thresh_match = cv2.resize(thresh_match, None, fx=scale, fy=scale)
  h, w = thresh_match.shape
  h_img, w_img = thresh_img.shape

  res = cv2.matchTemplate(thresh_img, thresh_match, cv2.TM_CCOEFF_NORMED)
  _, _, _, max_loc = cv2.minMaxLoc(res)
  top_left = max_loc
  bottom_right = (top_left[0] + w, top_left[1] + h)

  rect = thresh_img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
  # print(h, w)
  if (h / h_img * 100 < 2) and (w / w_img * 100 < 2):
    comp_scale = 50
  else:
    comp_scale = 1
  thresh_match_resized = cv2.resize(thresh_match, None, fx=comp_scale, fy=comp_scale)
  rect_resized = cv2.resize(rect, None, fx=comp_scale, fy=comp_scale)
  # simularity_score = 5
  simularity_score = metrics.structural_similarity(rect_resized, thresh_match_resized, win_size=3)
  # print(f"SSIM Score: ", round(simularity_score, 2))

  return top_left, bottom_right, simularity_score

def find_rect_center(rect):
  x1 = rect[0][0]
  x2 = rect[1][0]
  y1 = rect[0][1]
  y2 = rect[1][1]
  return ((x1 + x2) // 2, (y1 + y2) // 2)

# img_str = 'test_lock_cropped.jpg'
# device_str = 'device_cropped.png'
# key_str = 'sun_2.png'
# optimal_scale = find_optimal_scale(img_str, device_str)
# # optimal_scale = 0.380859375
# print("Scale:", optimal_scale)
# top_left, bottom_right, simularity_score = match_images(img_str, key_str, optimal_scale)
# img = cv2.imread(img_str, cv2.IMREAD_COLOR)
# if simularity_score > 0:
#   print(top_left, bottom_right)
#   cv2_imshow(crop(img,(top_left, bottom_right)))
#   print(key_str, "coords:", find_rect_center((top_left, bottom_right)))
# else:
#   print("NOT FOUND")